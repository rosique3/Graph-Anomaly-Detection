{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caa9a9d",
   "metadata": {},
   "source": [
    "¬°Absolutamente! Es una pregunta fundamental. Cuando se trabaja con un modelo no supervisado como el **Autoencoder de Grafos (GAE)**, el proceso se llama **entrenamiento**, pero el objetivo y la funci√≥n de p√©rdida son diferentes a los de un modelo supervisado.\n",
    "\n",
    "---\n",
    "\n",
    "## üèãÔ∏è Entrenamiento en Contexto No Supervisado\n",
    "\n",
    "Aunque tu problema es de detecci√≥n de anomal√≠as **no supervisada**, el GAE necesita una fase de entrenamiento para **aprender la estructura y los patrones de los datos \"normales\"**.\n",
    "\n",
    "### 1. El Objetivo del Entrenamiento\n",
    "\n",
    "En un modelo supervisado (clasificaci√≥n, regresi√≥n), el objetivo es predecir una etiqueta $Y$ a partir de los datos $X$.\n",
    "\n",
    "En el GAE (no supervisado), el objetivo es:\n",
    "\n",
    "> **Aprender la funci√≥n de identidad:** El modelo debe aprender a tomar el grafo (estructura $\\mathbf{A}$ y atributos $\\mathbf{X}$) y reconstruirse a s√≠ mismo ($\\mathbf{\\hat{A}}$ y $\\mathbf{\\hat{X}}$) con la **menor p√©rdida posible**.\n",
    "\n",
    "El modelo no sabe qu√© es una anomal√≠a; solo aprende a modelar la **mayor√≠a** de los datos (la poblaci√≥n normal).\n",
    "\n",
    "### 2. La Funci√≥n de P√©rdida (Loss Function)\n",
    "\n",
    "La funci√≥n de p√©rdida que utilizas es la que te permite entrenar el modelo sin etiquetas de anomal√≠a. Como ya mencionamos, se basa en la **p√©rdida de reconstrucci√≥n dual**:\n",
    "\n",
    "$$L = \\alpha \\cdot L_A(\\mathbf{A}, \\mathbf{\\hat{A}}) + \\beta \\cdot L_X(\\mathbf{X}, \\mathbf{\\hat{X}})$$\n",
    "\n",
    "* **Durante el entrenamiento**, el modelo ajusta sus pesos internos (los par√°metros de la GCN y los decodificadores) para **minimizar** este error $L$ en todo el *dataset*.\n",
    "\n",
    "### 3. La Detecci√≥n (Fase de Prueba)\n",
    "\n",
    "Una vez que el modelo est√° entrenado y converge (es decir, la p√©rdida ha dejado de disminuir significativamente), pasas a la fase de detecci√≥n:\n",
    "\n",
    "* **Para cada nodo $i$**, aplicas el modelo y calculas sus errores de reconstrucci√≥n *individuales* ($L_{A_i}$ y $L_{X_i}$).\n",
    "* Los nodos que el modelo no puede reconstruir bien (es decir, tienen una p√©rdida de reconstrucci√≥n muy alta) son los que se **desv√≠an** de los patrones aprendidos, y por lo tanto, se clasifican como **anomal√≠as**.\n",
    "\n",
    "**Conclusi√≥n:** En la pr√°ctica, el GAE sigue un proceso de entrenamiento por √©pocas y optimizaci√≥n (como Adam) similar a cualquier red neuronal, pero utiliza la **reconstrucci√≥n** en lugar de la predicci√≥n de etiquetas como su objetivo de aprendizaje. El *dataset* completo se usa como la muestra de \"datos normales\" para entrenar el modelo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
